---
layout: course-sidebar
title: Course Outline
subtitle: Spring 2026
---

# CPSY 1950 â€” Course Overview (Spring 2026)

## Core format
- T/Th, 80 minutes
- Tue = lecture introducing the week's theme (conceptual, figure-first)
- Thu = mini-conference (lightning talks) on the same theme  
  - ~15 lightning talks (2:00 talk + 0:30 transition)  
  - ~20â€“30 min synthesis discussion/activity

## Group & presentation plan (for up to 103 students)
- Lightning talks are prepared in small groups (typically 3, occasionally 4).
- Groups are not fixed: students will form new groups for each lightning week (rotating teams over the semester).
- Posters are reserved for student projects (after spring break).
- Equity: presentation turns are tracked at the individual student level so that each student presents the same number of times across the semester (lightning talks + the project poster).

# Schedule

## Week 1 â€” Course kickoff
<details>
<summary><strong>Thu 1/22 â€” Course Kickoff</strong></summary>
<p>NeuroAI goals, course structure, and how we will simulate scientific conferences (lightning talks and posters).</p>
<p><em>No readings or pre-class activities for Week 1â€”this is the introductory session.</em></p>
</details>

## Week 2 â€” Bootcamp (async; replaces Tue/Thu lectures)

<details>
<summary><strong>Tue 1/27 â€” Bootcamp I (async; completed during normal Tue class time)</strong></summary>

<p><strong>Assigned reading (all students):</strong></p>
<ul>
<li><a href="https://arxiv.org/pdf/2209.03718">Doerig et al. (2023) - The neuroconnectionist research programme</a></li>
</ul>

<p><strong>Deep learning intuition (conditional):</strong></p>
<p>Optional for everyone, but <strong>MANDATORY</strong> for students who have not taken a deep learning course.</p>
<ul>
<li><a href="https://www.3blue1brown.com/lessons/neural-networks">3Blue1Brown Ch.1: What is a neural network?</a></li>
<li><a href="https://www.3blue1brown.com/lessons/gradient-descent">3Blue1Brown Ch.2: Gradient descent</a></li>
<li><a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U">3Blue1Brown Ch.3: Backpropagation</a></li>
</ul>

<p><strong>Linear algebra bootcamp (conditional):</strong></p>
<p>Optional for everyone, but <strong>MANDATORY</strong> for students who have not taken linear algebra and have not taken any ML/AI course that used vectors/matrices seriously.</p>
<ul>
<li><a href="https://www.3blue1brown.com/lessons/vectors">3Blue1Brown: Vectors, what even are they?</a></li>
<li><a href="https://www.3blue1brown.com/lessons/span">3Blue1Brown: Linear combinations, span, and basis vectors</a></li>
<li><a href="https://www.3blue1brown.com/lessons/linear-transformations">3Blue1Brown: Linear transformations and matrices</a></li>
<li><a href="https://www.3blue1brown.com/lessons/matrix-multiplication">3Blue1Brown: Matrix multiplication as composition</a></li>
</ul>

<p><strong>Neuroscience intro video (conditional):</strong></p>
<p>Optional for everyone, but <strong>MANDATORY</strong> for students who have not taken an intro course in neuroscience and/or cognitive science and/or cognitive neuroscience.</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=nlSL7Qg7-Po">Neuroscience Introduction</a></li>
<li><a href="https://compneuro.neuromatch.io/tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial1.html">Neuromatch Academy W0D0</a></li>
<li><a href="https://youtube.com/watch?v=HCx-sOp9R7M">Lab Tour: Neural Data Context</a></li>
</ul>

<p><strong>Textbook-style foundations reading (conditional, skim):</strong></p>
<p>Optional for everyone, but <strong>MANDATORY</strong> for the same students who are required to watch the neuroscience intro video.</p>
<ul>
<li><a href="https://pressbooks.atlanticoer-relatlantique.ca/openneuroscience/chapter/chapter-2-anatomy-of-the-nervous-system/">Chapter 2 (brain organization / anatomy)</a></li>
<li><a href="https://pressbooks.atlanticoer-relatlantique.ca/openneuroscience/chapter/chapter-6/">Chapter 6 (methods overview)</a></li>
</ul>

</details>

<details>
<summary><strong>Thu 1/29 â€” Bootcamp II (async; completed during normal Thu class time)</strong></summary>

<p><strong>Assigned reading (all students):</strong></p>
<ul>
<li><a href="https://www-cell-com.revproxy.brown.edu/trends/cognitive-sciences/fulltext/S1364-6613%2819%2930034-8">Cichy & Kaiser (2019) - Deep Neural Networks as Scientific Models</a></li>
</ul>

<p><em>Note: Incorporate world models in reinforcement learning.</em></p>

</details>

## Week 3 â€” The three levers of deep learning
<details>
<summary><strong>Tue 2/3 â€” Lecture: The Three Levers of Deep Learning</strong></summary>
<p>How architecture, learning objectives, and experience (data/scale) shape representations, behavior, and generalization across modalities.</p>

<p><em>Note: Connect back to Nancy Kanwisher's examples of color and fruit detection in primates as the objective functions to be optimized / goal of the system/agent.</em></p>

<p><em>Note: Incorporate world models in reinforcement learning. See Ha & Schmidhuber (2018), <a href="https://arxiv.org/abs/1803.10122">World Models</a>.</em></p>
</details>

<details>
<summary><strong>Thu 2/5 â€” Lightning Mini-Conf 1: Three Levers of DL</strong></summary>
<p>Details TBD</p>
</details>

## Week 4 â€” Scaling and emerging capabilities
<details>
<summary><strong>Tue 2/10 â€” Lecture: Scaling and Emerging Capabilities</strong></summary>
<p>Pretraining and fine-tuning/transfer; in-context learning and reasoning; what 'emergence' claims mean and how to evaluate them critically.</p>
<p><a href="https://docs.google.com/presentation/d/1Tl2OR5kqpqh5MJIe1_DsQq20MZSS5G_6gkCzDDPblkc/edit?slide=id.g3c67357f7da_0_38#slide=id.g3c67357f7da_0_38" target="_blank">ðŸ“‘ Slides</a></p>
</details>

<details>
<summary><strong>Thu 2/12 â€” Lightning Mini-Conf 2: Scaling & Emergence</strong></summary>
<p>Details TBD</p>
</details>

## Week 5 â€” Prediction vs Understanding
<details>
<summary><strong>Tue 2/17 â€” No lecture (university holiday)</strong></summary>
<p>No class.</p>
</details>

<details>
<summary><strong>Thu 2/19 â€” Background reading and required viewing</strong></summary>
<p><strong>Background paper:</strong> Serre, T. &amp; Pavlick, E. (2025). From Prediction to Understanding: Will AI Foundation Models Transform Brain Science? <em>Neuron</em>. <a href="https://www-cell-com.revproxy.brown.edu/neuron/fulltext/S0896-6273(25)00752-4" target="_blank">Brown Library proxy</a>.</p>
<p><strong>Required viewing (watch both):</strong></p>
<ul>
<li>Marcus, G. (2024). <a href="https://www.youtube.com/watch?v=91SK90SahHc" target="_blank">Keynote at AGI-24</a>. Machine Learning Street Talk. Watch from ~5:00 to ~35:00.</li>
<li>LeCun, Y. (2024). <a href="https://www.youtube.com/watch?v=MiqLoAZFRSE" target="_blank">Objective-Driven AI</a>. Ding Shum Lecture, Harvard CMSA. Watch the first ~36 minutes.</li>
</ul>
<p>Paper response link TBD.</p>
</details>

## Week 6 â€” Representation-level interpretability
<details>
<summary><strong>Tue 2/24 â€” Lecture: Representation-Level Interpretability</strong></summary>
<p>Feature visualization, concept-based methods, sparse/dictionary approaches (incl. SAEs); what we can and can't reliably name in representations.</p>
</details>

<details>
<summary><strong>Thu 2/26 â€” Lightning Mini-Conf 4: Representation Interpretability</strong></summary>
<p>Details TBD</p>
</details>

## Week 7 â€” Mechanistic interpretability
<details>
<summary><strong>Tue 3/3 â€” Lecture: Mechanistic Interpretability</strong></summary>
<p>Circuits, causal interventions, and standards of evidence for mechanistic claims.</p>
</details>

<details>
<summary><strong>Thu 3/5 â€” Lightning Mini-Conf 5: Mechanistic Interpretability</strong></summary>
<p>Details TBD</p>
</details>

## Week 8 â€” Neural alignment
<details>
<summary><strong>Tue 3/10 â€” Lecture: Neural Alignment and Model-to-Brain Mapping</strong></summary>
<p>Predicting neural data across measurement modalities; encoding/decoding and representational similarity; what alignment can and cannot justify.</p>
</details>

<details>
<summary><strong>Thu 3/12 â€” Lightning Mini-Conf 6: Neural Alignment</strong></summary>
<p>Details TBD</p>
</details>

## Week 9 â€” Behavioral and cognitive alignment
<details>
<summary><strong>Tue 3/17 â€” Lecture: Behavioral and Cognitive Alignment</strong></summary>
<p>Treating models as participants in cognitive tasks; behavioral signatures beyond accuracy (generalization, planning, decision making, cognitive control); confounds and best practices.</p>
</details>

<details>
<summary><strong>Thu 3/19 â€” Lightning Mini-Conf 7: Behavioral Alignment</strong></summary>
<p>Details TBD</p>
</details>

## Week 10 â€” Spring Break
<details>
<summary><strong>Tue 3/24 â€” Spring Break</strong></summary>
<p>No class</p>
</details>

<details>
<summary><strong>Thu 3/26 â€” Spring Break</strong></summary>
<p>No class</p>
</details>

## Week 11 â€” Project studio
<details>
<summary><strong>Tue 3/31 â€” Project Studio I</strong></summary>
<p>Project launch and evaluation design; in-class time for groups to plan, run pilot tests, and produce first results/figures.</p>
</details>

<details>
<summary><strong>Thu 4/2 â€” Project Studio II</strong></summary>
<p>Continue project work: complete runs and draft poster.</p>
</details>

## Week 12 â€” Project poster presentations
<details>
<summary><strong>Tue 4/7 â€” Project Poster Mini-Conf A</strong></summary>
<p>Students present project findings in posters (17 posters); structured peer feedback and synthesis discussion.</p>
</details>

<details>
<summary><strong>Thu 4/9 â€” Project Poster Mini-Conf B</strong></summary>
<p>Students present project findings in posters (17 posters); structured peer feedback and synthesis discussion.</p>
</details>

## Week 13 â€” Guest lecture series
<details>
<summary><strong>Tue 4/14 â€” Guest Lecture Series I (TBD)</strong></summary>
<p>Details TBD</p>
</details>

<details>
<summary><strong>Thu 4/16 â€” Guest Lecture Series I (TBD)</strong></summary>
<p>Details TBD</p>
</details>

## Week 14 â€” Guest lecture series (continued)
<details>
<summary><strong>Tue 4/21 â€” Guest Lecture Series II: Rufin VanRullen</strong></summary>
<p>Frontier topics in NeuroAI: global workspace / consciousness & deep learning.</p>
</details>

<details>
<summary><strong>Thu 4/23 â€” Guest Lecture Series II: Victor Boutin + Course Wrap-Up</strong></summary>
<p>Frontier topics in NeuroAI: generative models, EBMs, cognitive science. Plus course wrap-up and final exam briefing.</p>
</details>

## Week 15 â€” Final exam
<details>
<summary><strong>Tue 5/12 â€” Final Exam</strong></summary>
<p>Final exam, 9:00am</p>
</details>
