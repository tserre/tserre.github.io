---
layout: course-sidebar
title: Course Outline
subtitle: Spring 2026
---

# CPSY 1950 — Course Overview (Spring 2026)

## Core format
- T/Th, 80 minutes
- Tue = lecture introducing the week's theme (conceptual, figure-first)
- Thu = lightning mini-conference on the same theme  
  - ~15 lightning talks (2:00 talk + 0:30 transition)  
  - ~20–30 min synthesis discussion/activity

## Group & presentation plan (for up to 103 students)
- Lightning talks are prepared in small groups (typically 3, occasionally 4).
- Groups are not fixed: students will form new groups for each lightning week (rotating teams over the semester).
- Posters are reserved for student projects (after spring break).
- Equity: presentation turns are tracked at the individual student level so that each student presents the same number of times across the semester (lightning talks + the project poster).

# Schedule

## Week 1 — Course kickoff
<details>
<summary><strong>Thu 1/22 — Course Kickoff</strong></summary>
<p>NeuroAI goals, course structure, and how we will simulate scientific conferences (lightning talks and posters).</p>
<p><em>No readings or pre-class activities for Week 1—this is the introductory session.</em></p>
</details>

## Week 2 — Bootcamp (async; replaces Tue/Thu lectures)

<details>
<summary><strong>Tue 1/27 — Bootcamp I (async; completed during normal Tue class time)</strong></summary>

<p><strong>Assigned reading (all students):</strong></p>
<ul>
<li><a href="https://arxiv.org/pdf/2209.03718">Doerig et al. (2023) - The neuroconnectionist research programme</a></li>
</ul>

<p><strong>Deep learning intuition (conditional):</strong></p>
<p>Optional for everyone, but <strong>MANDATORY</strong> for students who have not taken a deep learning course.</p>
<ul>
<li><a href="https://www.3blue1brown.com/lessons/neural-networks">3Blue1Brown Ch.1: What is a neural network?</a></li>
<li><a href="https://www.3blue1brown.com/lessons/gradient-descent">3Blue1Brown Ch.2: Gradient descent</a></li>
<li><a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U">3Blue1Brown Ch.3: Backpropagation</a></li>
</ul>

<p><strong>Linear algebra bootcamp (conditional):</strong></p>
<p>Optional for everyone, but <strong>MANDATORY</strong> for students who have not taken linear algebra and have not taken any ML/AI course that used vectors/matrices seriously.</p>
<ul>
<li><a href="https://www.3blue1brown.com/lessons/vectors">3Blue1Brown: Vectors, what even are they?</a></li>
<li><a href="https://www.3blue1brown.com/lessons/span">3Blue1Brown: Linear combinations, span, and basis vectors</a></li>
<li><a href="https://www.3blue1brown.com/lessons/linear-transformations">3Blue1Brown: Linear transformations and matrices</a></li>
<li><a href="https://www.3blue1brown.com/lessons/matrix-multiplication">3Blue1Brown: Matrix multiplication as composition</a></li>
</ul>

<p><strong>Neuroscience intro video (conditional):</strong></p>
<p>Optional for everyone, but <strong>MANDATORY</strong> for students who have not taken an intro course in neuroscience and/or cognitive science and/or cognitive neuroscience.</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=nlSL7Qg7-Po">Neuroscience Introduction</a></li>
<li><a href="https://compneuro.neuromatch.io/tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial1.html">Neuromatch Academy W0D0</a></li>
<li><a href="https://youtube.com/watch?v=HCx-sOp9R7M">Lab Tour: Neural Data Context</a></li>
</ul>

<p><strong>Textbook-style foundations reading (conditional, skim):</strong></p>
<p>Optional for everyone, but <strong>MANDATORY</strong> for the same students who are required to watch the neuroscience intro video.</p>
<ul>
<li><a href="https://pressbooks.atlanticoer-relatlantique.ca/openneuroscience/chapter/chapter-2-anatomy-of-the-nervous-system/">Chapter 2 (brain organization / anatomy)</a></li>
<li><a href="https://pressbooks.atlanticoer-relatlantique.ca/openneuroscience/chapter/chapter-6/">Chapter 6 (methods overview)</a></li>
</ul>

</details>

<details>
<summary><strong>Thu 1/29 — Bootcamp II (async; completed during normal Thu class time)</strong></summary>

<p><strong>Assigned reading (all students):</strong></p>
<ul>
<li><a href="https://www-cell-com.revproxy.brown.edu/trends/cognitive-sciences/fulltext/S1364-6613%2819%2930034-8">Cichy & Kaiser (2019) - Deep Neural Networks as Scientific Models</a></li>
</ul>

<p><em>Note: Incorporate world models in reinforcement learning.</em></p>

</details>

## Week 3 — The three levers of deep learning
<details>
<summary><strong>Tue 2/3 — Lecture: The Three Levers of Deep Learning</strong></summary>
<p>How architecture, learning objectives, and experience (data/scale) shape representations, behavior, and generalization across modalities.</p>

<p><em>Note: Connect back to Nancy Kanwisher's examples of color and fruit detection in primates as the objective functions to be optimized / goal of the system/agent.</em></p>

<p><em>Note: Incorporate world models in reinforcement learning. See Ha & Schmidhuber (2018), <a href="https://arxiv.org/abs/1803.10122">World Models</a>.</em></p>
</details>

<details>
<summary><strong>Thu 2/5 — Lightning Mini-Conf 1: Three Levers of DL</strong></summary>
<p>Details TBD</p>
</details>

## Week 4 — Scaling and emerging capabilities
<details>
<summary><strong>Tue 2/10 — Lecture: Scaling and Emerging Capabilities</strong></summary>
<p>Pretraining and fine-tuning/transfer; in-context learning and reasoning; what 'emergence' claims mean and how to evaluate them critically.</p>
</details>

<details>
<summary><strong>Thu 2/12 — Lightning Mini-Conf 2: Scaling & Emergence</strong></summary>
<p>Details TBD</p>
</details>

## Week 5 — Representation-level interpretability
<details>
<summary><strong>Tue 2/17 — Lecture: Representation-Level Interpretability</strong></summary>
<p>Feature visualization, concept-based methods, sparse/dictionary approaches (incl. SAEs); what we can and can't reliably name in representations.</p>
</details>

<details>
<summary><strong>Thu 2/19 — Lightning Mini-Conf 3: Representation Interpretability</strong></summary>
<p>Details TBD</p>
</details>

## Week 6 — Mechanistic interpretability
<details>
<summary><strong>Tue 2/24 — Lecture: Mechanistic Interpretability</strong></summary>
<p>Circuits, causal interventions, and standards of evidence for mechanistic claims.</p>
</details>

<details>
<summary><strong>Thu 2/26 — Lightning Mini-Conf 4: Mechanistic Interpretability</strong></summary>
<p>Details TBD</p>
</details>

## Week 7 — Neural alignment
<details>
<summary><strong>Tue 3/3 — Lecture: Neural Alignment and Model-to-Brain Mapping</strong></summary>
<p>Predicting neural data across measurement modalities; encoding/decoding and representational similarity; what alignment can and cannot justify.</p>
</details>

<details>
<summary><strong>Thu 3/5 — Lightning Mini-Conf 5: Neural Alignment</strong></summary>
<p>Details TBD</p>
</details>

## Week 8 — Behavioral and cognitive alignment
<details>
<summary><strong>Tue 3/10 — Lecture: Behavioral and Cognitive Alignment</strong></summary>
<p>Treating models as participants in cognitive tasks; behavioral signatures beyond accuracy (generalization, planning, decision making, cognitive control); confounds and best practices.</p>
</details>

<details>
<summary><strong>Thu 3/12 — Lightning Mini-Conf 6: Behavioral Alignment</strong></summary>
<p>Details TBD</p>
</details>

## Week 9 — Toward Brain-Like AI
<details>
<summary><strong>Tue 3/17 — Lecture: Toward Brain-Like AI (Project Launch)</strong></summary>
<p>Brain-like training (developmental curricula, data diet, objectives) and brain-like mechanisms (recurrence/feedback, circuit motifs, robustness); translating hypotheses into concrete evaluation plans.</p>
<p><em>Note: Incorporate hippocampus-inspired architectures for continual learning and embodied AI approaches. Also cover connectomics constraints and neuronal diversity.</em></p>
</details>

<details>
<summary><strong>Thu 3/19 — Lightning Mini-Conf 7: Brain-Like AI + Project Launch</strong></summary>
<p>Details TBD</p>
</details>

## Week 10 — Spring Break
<details>
<summary><strong>Tue 3/24 — Spring Break</strong></summary>
<p>No class</p>
</details>

<details>
<summary><strong>Thu 3/26 — Spring Break</strong></summary>
<p>No class</p>
</details>

## Week 11 — Project studio
<details>
<summary><strong>Tue 3/31 — Project Studio I</strong></summary>
<p>Project launch and evaluation design; in-class time for groups to plan, run pilot tests, and produce first results/figures.</p>
</details>

<details>
<summary><strong>Thu 4/2 — Project Studio II</strong></summary>
<p>Continue project work: complete runs and draft poster.</p>
</details>

## Week 12 — Project poster presentations
<details>
<summary><strong>Tue 4/7 — Project Poster Mini-Conf A</strong></summary>
<p>Students present project findings in posters (17 posters); structured peer feedback and synthesis discussion.</p>
</details>

<details>
<summary><strong>Thu 4/9 — Project Poster Mini-Conf B</strong></summary>
<p>Students present project findings in posters (17 posters); structured peer feedback and synthesis discussion.</p>
</details>

## Week 13 — Guest lecture series
<details>
<summary><strong>Tue 4/14 — Guest Lecture Series I (TBD)</strong></summary>
<p>Details TBD</p>
</details>

<details>
<summary><strong>Thu 4/16 — Guest Lecture Series I (TBD)</strong></summary>
<p>Details TBD</p>
</details>

## Week 14 — Guest lecture series (continued)
<details>
<summary><strong>Tue 4/21 — Guest Lecture Series II: Rufin VanRullen</strong></summary>
<p>Frontier topics in NeuroAI: global workspace / consciousness & deep learning.</p>
</details>

<details>
<summary><strong>Thu 4/23 — Guest Lecture Series II: Victor Boutin + Course Wrap-Up</strong></summary>
<p>Frontier topics in NeuroAI: generative models, EBMs, cognitive science. Plus course wrap-up and final exam briefing.</p>
</details>

## Week 15 — Final exam
<details>
<summary><strong>Tue 5/12 — Final Exam</strong></summary>
<p>Final exam, 9:00am</p>
</details>
