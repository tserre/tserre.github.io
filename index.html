---
layout: default
title: Thomas Serre - Brown University
---
<head>
    <!-- Basic Meta Tags -->
    <meta name="description" content="Thomas Serre is the Thomas J. Watson, Sr. Professor of Science at Brown University. Research in computational neuroscience, AI, and brain-inspired vision models.">
    <meta name="keywords" content="Thomas Serre, Brown University, computational neuroscience, artificial intelligence, AI, NeuroAI, computer vision, deep learning, explainable AI, visual perception, CRAFT, MACO, Xplique">
    <meta name="author" content="Thomas Serre">
    
    <!-- Open Graph Meta Tags (for social media sharing) -->
    <meta property="og:title" content="Thomas Serre - Computational Neuroscience & AI">
    <meta property="og:description" content="Professor of Cognitive & Psychological Sciences and Computer Science at Brown University. Research at the intersection of neuroscience and AI.">
    <meta property="og:image" content="https://vivo.brown.edu/profile-images/a20/107/457/8fe/466/2b8/4d3/698/9fd/411/55/tserre_photo_.jpeg">
    <meta property="og:url" content="https://your-domain.com">
    
    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Thomas Serre - Brown University">
    <meta name="twitter:description" content="Research in computational neuroscience and brain-inspired AI at Brown University">
    
    <!-- Structured Data (JSON-LD) for Google -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "Person",
        "name": "Thomas Serre",
        "jobTitle": "Thomas J. Watson, Sr. Professor of Science",
        "affiliation": [
            {
                "@type": "Organization",
                "name": "Brown University"
            },
            {
                "@type": "Organization", 
                "name": "Artificial and Natural Intelligence Toulouse Institute (ANITI)"
            }
        ],
        "url": "https://your-domain.com",
        "sameAs": [
            "https://scholar.google.com/citations?user=kZlPW4wAAAAJ",
            "https://github.com/serre-lab",
            "https://serre-lab.clps.brown.edu/"
        ],
        "alumniOf": {
            "@type": "Organization",
            "name": "MIT"
        }
    }
    </script>
</head>
<img src="https://vivo.brown.edu/profile-images/a20/107/457/8fe/466/2b8/4d3/698/9fd/411/55/tserre_photo_.jpeg" alt="Thomas Serre" style="float: right; margin: 0 0 20px 20px; max-width: 200px; border-radius: 8px;">

Thomas Serre is the Thomas J. Watson, Sr. Professor of Science and Professor of <a href="https://brown.edu/academics/cognitive-linguistic-psychological-sciences">Cognitive & Psychological Sciences</a> and <a href="https://cs.brown.edu/">Computer Science</a> at Brown University.<br>

He is the Faculty Director of the <a href="https://ccv.brown.edu/">Center for Computation and Visualization</a> and Associate Director of the <a href="https://ccbs.brown.edu/">Center for Computational Brain Science</a>. He also holds an International Chair in AI within the <a href="https://aniti.univ-toulouse.fr/">Artificial and Natural Intelligence Toulouse Institute (ANITI)</a> (France).<br>
Dr. Serre received his Ph.D. in Neuroscience from MIT (2006) and MSc in EECS from Télécom Bretagne, France (2000).<br>

His research focuses on understanding neural computations supporting visual perception, with particular emphasis on the role of recurrent and feedback processes in visual reasoning. His work bridges neuroscience and artificial intelligence, developing brain-inspired computational models that have been featured in outlets including BBC, The Economist, New Scientist, and Scientific American.<br>

Dr. Serre serves as area chair for top-tier conferences including CVPR, ICML, ICLR, and NeurIPS, and as section editor for PLOS Computational Biology.<br>

He received an NSF Early Career Award and DARPA Young Faculty Award. His team's work on human action recognition earned the IEEE PAMI Helmholtz Prize (2021) and Mark Everingham Prize (2022). <br><br>


<h2>Research</h2>

My research investigates the computational principles of biological vision to build more human-like AI systems. I work at the intersection of neuroscience, cognitive science, and artificial intelligence.<br><br>

<h3>Current Research Directions</h3>

<b>Human-AI Alignment in Vision</b><br>
We're developing methods to quantify and improve the alignment between deep neural networks and human visual processing. Our <a href="https://arxiv.org/abs/2504.16940">recent work</a> shows that despite impressive performance, current vision models still process information fundamentally differently from humans. Understanding these gaps is crucial for building more robust and interpretable AI systems and to understand the brain mechanisms that support human vision. <i>Funded by NSF</i><br><br>

<b>Explainable AI for Scientific Discovery</b><br>
In collaboration with the <a href="https://aniti.univ-toulouse.fr/">Artificial and Natural Intelligence Toulouse Institute (ANITI)</a>, we're creating tools to understand and interpret deep learning models. Our <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Fel_CRAFT_Concept_Recursive_Activation_FacTorization_for_Explainability_CVPR_2023_paper.pdf">CRAFT framework</a> (Fel et al., CVPR 2023) and <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/76d2f8e328e1081c22a77ca0fa330ca5-Abstract-Conference.html">MACO approach</a> (Fel et al., NeurIPS 2023) help researchers peek inside the "black box" of AI. CRAFT provides concept-based explanations that reveal both "what" and "where" models look, while MACO unlocks feature visualization for state-of-the-art deep networks. These methods are implemented in our open-source <a href="https://github.com/deel-ai/xplique">Xplique toolbox</a>, making explainability accessible to the broader research community. See these tools in action: <a href="https://serre-lab.github.io/Lens/">LENS</a> explains what ImageNet models really see, and <a href="https://serre-lab.github.io/LeafLens/">LeafLens</a> reveals how AI identifies plant species from cleared leaves. We're now extending this work to build <a href="https://www.arxiv.org/abs/2509.17280">foundation models for neuroscience and cognitive science</a>. <br><br>
<b>Cortical Feedback and Visual Reasoning</b><br>
We're reverse-engineering how feedback connections in the brain enable complex visual reasoning and mental simulation. Our <a href="https://www.cell.com/current-biology/fulltext/S0960-9822(24)01380-0">recent work</a> reveals that both monkeys and recurrent neural networks use internal "mental simulations" to solve challenging visual tasks—suggesting deep computational principles shared between biological and artificial intelligence. <i>Funded by ONR</i><br><br>

<h2>Teaching</h2>

I teach computational courses at the interface between natural and artificial intelligence, bridging neuroscience, cognitive science, and AI.<br><br>

<b>CLPS 1291: Computational Methods for Mind, Brain & Behavior</b><br>
<i>Undergraduate, Fall Semester</i><br>
A broad introduction to NeuroAI combining lectures with hands-on programming assignments. Students explore computational models of brain and cognition, classical machine learning algorithms, and modern deep learning architectures.<br><br>

<b>CLPS 1950: Deep Learning in Brains, Minds & Machines</b><br>
<i>Advanced Undergraduate/Graduate, Spring Semester</i><br>
A seminar-style exploration of cutting-edge research at the intersection of natural and artificial intelligence. Students engage with recent papers and develop critical perspectives on how biological and artificial systems process information.<br><br>

<h2>Selected Recent Publications</h2>

- D. Linsley, P. Feng & T. Serre (2025). <a href="https://arxiv.org/abs/2504.16940">Better artificial intelligence does not mean better models of biology</a>. <i>arXiv preprint</i>.<br>
- A. Ahuja et al. (2024). <a href="https://www.cell.com/current-biology/fulltext/S0960-9822(24)01380-0">Monkeys engage in visual simulation to solve complex problems</a>. <i>Current Biology</i>.<br>
- T. Fel et al. (2023). <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/76d2f8e328e1081c22a77ca0fa330ca5-Abstract-Conference.html">MACO: Unlocking feature visualization for deeper networks</a>. <i>NeurIPS</i>.<br>
- T. Fel et al. (2023). <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Fel_CRAFT_Concept_Recursive_Activation_FacTorization_for_Explainability_CVPR_2023_paper.pdf">CRAFT: Concept Recursive Activation FacTorization for Explainability</a>. <i>CVPR</i>.<br>


<h2>Lab & Resources</h2>

For more information about our research, team, and open-source tools:<br>
- <a href="https://serre-lab.clps.brown.edu/">Serre Lab website</a><br>
- <a href="https://scholar.google.com/citations?user=kZlPW4wAAAAJ&hl=en&oi=ao">Google Scholar</a> <br>
- <a href="https://github.com/serre-lab">GitHub</a> - Code and tools<br>
- <a href="https://github.com/deel-ai/xplique">Xplique</a> - Explainable AI toolbox<br><br>

<h2>Contact</h2>

Thomas Serre<br>
Brown University<br>
Providence, RI 02912<br>
Email: firstname_lastname@brown.edu<br>


