---
layout: default
title: Thomas Serre - Computational Neuroscience & AI Research
---
<head>
    <!-- Basic Meta Tags -->
    <meta name="description" content="Thomas Serre is the Thomas J. Watson, Sr. Professor of Science at Brown University. Research in Machine and Biological Vision, Computational Neuroscience, AI, NeuroAI, and XAI.">
    <meta name="keywords" content="Machine and Biological Vision • Computational neuroscience • AI • NeuroAI • XAI">
    <meta name="author" content="Thomas Serre">
    <meta name="robots" content="index, follow">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="UTF-8">
    
    <!-- Google Search Console Verification -->
    <meta name="google-site-verification" content="ejJP3EzEPiiDAocOP7Xx5FmgCY4Mvhki3BOGf8_NjE0">
    
    
    <!-- Open Graph Meta Tags (for social media sharing) -->
    <meta property="og:title" content="Thomas Serre - Computational Neuroscience & AI">
    <meta property="og:description" content="Professor of Cognitive & Psychological Sciences and Computer Science at Brown University. Research at the intersection of neuroscience and AI.">
    <meta property="og:image" content="https://vivo.brown.edu/profile-images/a20/107/457/8fe/466/2b8/4d3/698/9fd/411/55/tserre_photo_.jpeg">
    <meta property="og:url" content="https://thomas-serre.com">
    <meta property="og:type" content="website">
    <meta property="og:site_name" content="Thomas Serre - Brown University">
    
    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@tserre">
    <meta name="twitter:creator" content="@tserre">
    <meta name="twitter:title" content="Thomas Serre - Brown University">
    <meta name="twitter:description" content="Research in computational neuroscience and brain-inspired AI at Brown University">
    
    <!-- Structured Data (JSON-LD) for Google -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "Person",
        "name": "Thomas Serre",
        "jobTitle": "Thomas J. Watson, Sr. Professor of Science",
        "affiliation": [
            {
                "@type": "Organization",
                "name": "Brown University"
            },
            {
                "@type": "Organization", 
                "name": "Artificial and Natural Intelligence Toulouse Institute (ANITI)"
            }
        ],
        "url": "https://thomas-serre.com",
        "description": "Thomas Serre is the Thomas J. Watson, Sr. Professor of Science at Brown University. Research in Machine and Biological Vision, Computational Neuroscience, AI, NeuroAI, and XAI.",
        "image": "https://vivo.brown.edu/profile-images/a20/107/457/8fe/466/2b8/4d3/698/9fd/411/55/tserre_photo_.jpeg",
        "worksFor": [
            {
                "@type": "Organization",
                "name": "Brown University",
                "department": "Cognitive & Psychological Sciences and Computer Science"
            }
        ],
        "hasOccupation": {
            "@type": "Occupation",
            "name": "Professor",
            "occupationLocation": {
                "@type": "Place",
                "name": "Brown University"
            }
        },
        "knowsAbout": [
            "Vision",
            "Computational Neuroscience",
            "AI",
            "NeuroAI",
            "XAI",
            "Artificial Intelligence",
            "Computer Vision",
            "Deep Learning",
            "Explainable AI",
            "Visual Perception",
            "Cognitive Science",
            "Machine Learning",
            "Neural Networks"
        ],
        "sameAs": [
            "https://scholar.google.com/citations?user=kZlPW4wAAAAJ",
            "https://github.com/serre-lab",
            "https://serre-lab.clps.brown.edu/",
            "https://x.com/tserre",
            "https://bsky.app/profile/thomasserre.bsky.social",
            "https://www.linkedin.com/in/thomasserre/"
        ],
        "alumniOf": {
            "@type": "Organization",
            "name": "MIT"
        }
    }
    </script>
    
    <!-- Custom styles for CV-inspired formatting -->
    <style>
    /* Style bullet separators to be gray, matching CV style */
    section p, section i {
        color: inherit;
    }
    
    /* Add subtle gray color to bullet delimiters while keeping surrounding text normal */
    section {
        line-height: 1.6;
    }
    
    /* Make grant descriptions slightly more compact */
    .grant-description {
        margin-top: 0.3em;
        line-height: 1.5;
    }
    
    /* Section header styling matching main title blue */
    h2 {
        color: #0366d6;
        border-bottom: 3px solid #0366d6;
        padding-bottom: 0.3em;
        margin-top: 1.5em;
        font-weight: 600;
    }
    
    h3 {
        color: #0366d6;
        font-weight: 600;
        margin-top: 1.2em;
    }
    </style>
</head>
<img src="https://vivo.brown.edu/profile-images/a20/107/457/8fe/466/2b8/4d3/698/9fd/411/55/tserre_photo_.jpeg" alt="Thomas Serre" style="float: right; margin: 0 0 20px 20px; max-width: 200px; border-radius: 8px;">

Thomas Serre is the Thomas J. Watson, Sr. Professor of Science and Professor of <a href="https://brown.edu/academics/cognitive-linguistic-psychological-sciences">Cognitive & Psychological Sciences</a> and <a href="https://cs.brown.edu/">Computer Science</a> at Brown University <span style="color: #888;">•</span> He serves as Faculty Director of the <a href="https://ccv.brown.edu/">Center for Computation and Visualization</a> and Associate Director of the <a href="https://ccbs.carney.brown.edu/">Center for Computational Brain Science</a>. He is an affiliate faculty member of the <a href="https://brown.edu/academics/physics/centers/theoretical-physics-innovation">Brown Center for Theoretical Physics and Innovation</a> and the <a href="https://dsi.brown.edu/">Data Science Institute</a>, and holds an International Chair in AI at the <a href="https://aniti.univ-toulouse.fr/">Artificial and Natural Intelligence Toulouse Institute (ANITI)</a> in France <span style="color: #888;">•</span> Dr. Serre received his Ph.D. in Neuroscience from MIT (2006) and M.Sc. in Electrical Engineering and Computer Science from Télécom Bretagne, France (2000) <span style="color: #888;">•</span> His research focuses on understanding the neural computations that support visual perception, with particular emphasis on the role of recurrent and feedback processes in visual reasoning. His work bridges neuroscience and artificial intelligence by developing brain-inspired computational models. This work has been featured in prominent outlets including the BBC, The Economist, New Scientist, and Scientific American <span style="color: #888;">•</span> Dr. Serre serves as area chair for leading AI conferences (CVPR, ICML, ICLR, NeurIPS) and as Neuroscience section editor for PLOS Computational Biology <span style="color: #888;">•</span> His honors include the NSF Early Career Award, DARPA Young Faculty Award, and DARPA Director's Award. His team was awarded the 2021 PAMI Helmholtz Prize and the 2022 PAMI Mark Everingham Prize for their contributions to human action recognition.<br><br>

<h2>Research</h2>

My research investigates the computational principles of biological vision—both to understand how the brain works and to build more human-like AI systems. Working at the intersection of neuroscience, cognitive science, and artificial intelligence, my lab tackles a fundamental question: How can we bridge the gap between biological and artificial vision to advance both brain science and AI?<br><br>

<b>Human-AI Alignment in Vision</b><br>
We develop methods to quantify and improve the alignment between deep neural networks and human visual processing. Our <a href="https://arxiv.org/abs/2504.16940">recent work</a> reveals that despite impressive performance, current vision models process information fundamentally differently from humans—a critical gap for both building robust AI systems and understanding brain mechanisms. Importantly, our harmonization procedure shows that alignment can be dramatically improved without changing network architectures, suggesting the misalignment stems from training procedures rather than structural limitations. This insight has motivated us to adopt a <a href="https://openreview.net/forum?id=KeiQNpb7sv">developmental psychology approach</a>: we identify the learning principles and developmental trajectories that shape human vision, then incorporate these principles into AI training to create models that not only perform well but see the world as humans do. <i>Funded by NSF.</i><br><br>

<b>Cognitive Benchmarks for AI Visual Reasoning</b><br>
We develop rigorous cognitive-psychology-inspired benchmarks to evaluate fundamental gaps between human and machine vision. These benchmarks reveal systematic failures in modern AI. For example, our <a href="https://proceedings.neurips.cc/paper/2018/hash/ec8956637a99787bd197eacd77acce5e-Abstract.html">Pathfinder challenge</a> shows that feedforward networks fail at contour integration tasks that humans solve effortlessly—a finding later confirmed by <a href="https://arxiv.org/pdf/2011.04006">Google DeepMind</a>, who showed that even state-of-the-art transformers fail while our brain-inspired recurrent models succeed. Our <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/c08ee8fe3d19521f3bfa4102898329fd-Abstract-Datasets_and_Benchmarks.html">compositional reasoning benchmark</a> reveals AI's inability to flexibly combine visual concepts, while our <a href="https://openreview.net/forum?id=UIFAJZ22ZF">3D-PC benchmark</a> demonstrates failures in visual perspective-taking—a key signature of theory of mind. Even seemingly simple <a href="https://royalsocietypublishing.org/doi/10.1098/rsfs.2018.0011">same-different judgments</a> expose how neural networks struggle with basic visual relationships. Critically, this work not only reveals AI limitations but also helps identify <a href="https://www.eneuro.org/content/8/1/ENEURO.0267-20.2020">brain mechanisms underlying relational processing</a>. <i>Funded by ONR.</i><br><br>

<b>Cortical Feedback and Visual Reasoning</b><br>
We reverse-engineer how feedback connections in the brain enable complex visual reasoning and mental simulation. Our cognitive benchmarks reveal systematic failures of feedforward networks—from contour integration to relational judgments—pinpointing which computations require recurrent processing. These insights guide our experimental work: our <a href="https://www.eneuro.org/content/8/1/ENEURO.0267-20.2020">neurophysiology studies</a> show that same-different tasks that challenge feedforward AI engage distinct neural dynamics in primates, while our <a href="https://www.cell.com/current-biology/fulltext/S0960-9822(24)01380-0">recent work</a> reveals that both monkeys and recurrent neural networks use internal "mental simulations" to solve challenging visual tasks. By identifying where feedforward processing fails, we pinpoint the computational role of cortical feedback. This work is reshaping our understanding of how biological vision achieves robust reasoning through recurrent processing. <i>Funded by ONR.</i><br><br>

<b>Explainable AI for Scientific Discovery</b><br>
In collaboration with the Artificial and Natural Intelligence Toulouse Institute, we create tools to understand and interpret deep learning models. Our <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Fel_CRAFT_Concept_Recursive_Activation_FacTorization_for_Explainability_CVPR_2023_paper.pdf">CRAFT framework</a> and <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/76d2f8e328e1081c22a77ca0fa330ca5-Abstract-Conference.html">MACO approach</a> help researchers open the "black box" of AI. CRAFT provides concept-based explanations revealing both "what" and "where" models look, while MACO enables feature visualization for state-of-the-art deep networks. These methods are implemented in our open-source <a href="https://github.com/deel-ai/xplique">Xplique toolbox</a>, making explainability accessible to the broader research community. Critically, our tools reveal when AI learns <a href="https://onlinelibrary.wiley.com/doi/10.1111/his.15180">deceptive strategies</a>—for instance, in histopathology, we showed that models claiming superhuman cancer diagnosis actually relied on spurious correlations rather than meaningful biological features. See these tools in action: <a href="https://serre-lab.github.io/Lens/">LENS</a> explains what ImageNet models actually see, and <a href="https://serre-lab.github.io/LeafLens/">LeafLens</a> reveals how AI identifies plant species from cleared leaves. Building on this work, we are developing methods to identify computational mechanisms learned by foundation models—an effort outlined in our <a href="https://arxiv.org/abs/2509.17280">perspective on moving from prediction to understanding in brain science</a>. <i>Funded by ANR and NSF.</i><br><br>

<h2>Teaching</h2>

I teach computational courses at the interface between natural and artificial intelligence, bridging neuroscience, cognitive science, and AI.<br><br>

<b>CPSY 1291: Computational Methods for Mind, Brain & Behavior</b><br>
<i>Advanced Undergraduate/Graduate <span style="color: #888;">•</span> Fall Semester</i><br>
A broad introduction to NeuroAI combining lectures with hands-on programming assignments. Students explore computational models of brain and cognition, classical machine learning algorithms, and modern deep learning architectures.<br><br>

<b>CPSY 1950: Deep Learning in Brains, Minds & Machines</b><br>
<i>Advanced Undergraduate/Graduate <span style="color: #888;">•</span> Spring Semester</i><br>
A seminar-style exploration of cutting-edge research at the intersection of natural and artificial intelligence. Students engage with recent papers and develop critical perspectives on how biological and artificial systems process information.<br><br>

<h2>Selected Recent Publications</h2>

<ul style="list-style-type: disc; padding-left: 1.5em; margin-top: 0.5em;">
<li style="margin-bottom: 0.5em;">T. Serre & E. Pavlick <span style="color: #888;">•</span> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0896627325007524">From Prediction to Understanding: Will AI Foundation Models Transform Brain Science?</a> <span style="color: #888;">•</span> <i>Neuron</i> <span style="color: #888;">•</span> 2025</li>
<li style="margin-bottom: 0.5em;">P. Roelfsema & T. Serre <span style="color: #888;">•</span> <a href="https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(25)00232-3">Feature binding in biological and artificial vision</a> <span style="color: #888;">•</span> <i>Trends in Cognitive Sciences</i> <span style="color: #888;">•</span> 2025</li>
<li style="margin-bottom: 0.5em;">D. Linsley et al. <span style="color: #888;">•</span> <a href="https://openreview.net/forum?id=UIFAJZ22ZF">The 3D-PC: A benchmark for visual perspective taking in humans and machines</a> <span style="color: #888;">•</span> <i>ICLR</i> <span style="color: #888;">•</span> 2025</li>
<li style="margin-bottom: 0.5em;">D. Linsley, P. Feng & T. Serre <span style="color: #888;">•</span> <a href="https://arxiv.org/abs/2504.16940">Better artificial intelligence does not mean better models of biology</a> <span style="color: #888;">•</span> <i>Trends in Cognitive Sciences</i> <span style="color: #888;">•</span> 2025</li>
<li style="margin-bottom: 0.5em;">S. Shahamatdar et al. <span style="color: #888;">•</span> <a href="https://onlinelibrary.wiley.com/doi/10.1111/his.15180">Deceptive learning in histopathology</a> <span style="color: #888;">•</span> <i>Histopathology</i> <span style="color: #888;">•</span> 2024</li>
<li style="margin-bottom: 0.5em;">A. Ahuja et al. <span style="color: #888;">•</span> <a href="https://www.cell.com/current-biology/fulltext/S0960-9822(24)01380-0">Monkeys engage in visual simulation to solve complex problems</a> <span style="color: #888;">•</span> <i>Current Biology</i> <span style="color: #888;">•</span> 2024</li>
</ul>

<p>See the <a href="https://serre-lab.clps.brown.edu/publications">lab publications page</a> for a complete list of publications.</p><br>

<h2>Selected Talks</h2>

<div style="margin-top: 1em;">

<div style="margin-bottom: 2em;">
<b>Aligning deep networks with primate vision via self-supervised learning</b><br>
<i>Simons Foundation Workshop on "Self Supervised Learning" <span style="color: #888;">•</span> May 2025</i><br>
<p style="margin: 0.5em 0;">Exploring how self-supervised learning can bridge the gap between artificial neural networks and biological vision systems. This talk presents our latest work on developing training procedures that align deep neural networks with primate visual processing, demonstrating that alignment can be dramatically improved without changing network architectures.</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; margin-top: 1em;">
<iframe src="https://www.youtube.com/embed/qDz-nZnioeg" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;" allowfullscreen allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe>
</div>
</div>

<div style="margin-bottom: 2em;">
<b>Feedforward and feedback processes in visual reasoning</b><br>
<i>MindCORE Vision Seminar, University of Pennsylvania <span style="color: #888;">•</span> April 2024</i><br>
<p style="margin: 0.5em 0;">Demonstrating how feedforward neural networks struggle with visual reasoning problems that appear simple to humans. This talk presents our computational neuroscience model of feedback circuitry in the visual cortex, showing how it can be transformed into a modern deep recurrent network that addresses weaknesses of current state-of-the-art feedforward networks—providing evidence that neuroscience can offer powerful new concepts for AI.</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; margin-top: 1em;">
<iframe src="https://www.youtube.com/embed/85fdDvpaHGE" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;" allowfullscreen allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe>
</div>
</div>

</div><br>

<h2>Active Grants</h2>

<ul style="list-style-type: none; padding-left: 0; margin-top: 0.5em;">
<li style="margin-bottom: 0.75em;"><b>High-performance compute cluster for brain science</b><br>
<i>NIH S10OD036341 <span style="color: #888;">•</span> 2025 – 2030 <span style="color: #888;">•</span> PI</i><br>
Supporting acquisition of a state-of-the-art high-performance computing cluster for large-scale computational neuroscience modeling and deep learning experiments.</li>
<li style="margin-bottom: 0.75em;"><b>One vision: Computational alignment of deep neural networks with humans</b><br>
<i>NSF IIS-2402875 <span style="color: #888;">•</span> 2024 – 2028 <span style="color: #888;">•</span> co-PI (Serre/Linsley)</i><br>
Developing methods to quantify and improve alignment between deep neural networks and human visual processing using developmental psychology approaches.</li>
<li style="margin-bottom: 0.75em;"><b>Brain-inspired deep learning models of visual reasoning</b><br>
<i>ONR N00014-24-1-2026 <span style="color: #888;">•</span> 2023 – 2028 <span style="color: #888;">•</span> PI</i><br>
Investigating computational principles underlying visual reasoning to develop more capable AI through cognitive benchmarks and brain-inspired architectures.</li>
<li style="margin-bottom: 0.75em;"><b>Brown Postdoctoral Training Program in Computational Psychiatry</b><br>
<i>NIH/NIMH 5T32MH126388 <span style="color: #888;">•</span> 2021 – 2026 <span style="color: #888;">•</span> co-PI (Frank/Rasmussen/Serre)</i><br>
Training postdoctoral fellows at the intersection of computational neuroscience, machine learning, and psychiatry to develop computational methods for understanding psychiatric disorders.</li>
<li style="margin-bottom: 0.75em;"><b>REPRISM: Flexible embodied problem-solving by manipulating the representational prism</b><br>
<i>ONR MURI N00014-24-1-2603 <span style="color: #888;">•</span> 2024 – 2027 <span style="color: #888;">•</span> co-I (PI: Konidaris)</i><br>
Developing vision systems that adaptively change representations based on task demands for flexible and generalizable problem-solving.</li>
<li style="margin-bottom: 0.75em;"><b>SEA-CROGS: Scalable, efficient and accelerated causal reasoning operators, graphs and spikes</b><br>
<i>DOE DE-SC0023191 <span style="color: #888;">•</span> 2022 – 2027 <span style="color: #888;">•</span> co-I (PI: Maxey)</i><br>
Creating scalable causal reasoning methods combining graph-based representations, spiking neural networks, and causal inference for Earth system science.</li>
<li style="margin-bottom: 0.75em;"><b>Secondary analysis of resting state MEG data using the Human Neocortical Neurosolver</b><br>
<i>NIH/NIMH 1RF1MH130415 <span style="color: #888;">•</span> 2022 – 2025 <span style="color: #888;">•</span> co-I (PI: Jones)</i><br>
Interpreting magnetoencephalography signals at cellular and circuit levels to understand neural mechanisms underlying resting state brain activity.</li>
<li style="margin-bottom: 0.75em;"><b>The next generation of operator regression networks: Theory, algorithms, applications</b><br>
<i>ONR N00014-22-1-2795 <span style="color: #888;">•</span> 2022 – 2027 <span style="color: #888;">•</span> co-I (PI: Karniadakis)</i><br>
Advancing theoretical foundations and practical applications of operator regression networks for solving partial differential equations and modeling physical systems.</li>
</ul>
