---
layout: default
title: Thomas Serre - NeuroAi
---
<head>
    <!-- Basic Meta Tags -->
    <meta name="description" content="Thomas Serre is the Thomas J. Watson, Sr. Professor of Science at Brown University. Research in computational neuroscience, AI, and brain-inspired vision models.">
    <meta name="keywords" content="Thomas Serre, Brown University, computational neuroscience, artificial intelligence, AI, NeuroAI, computer vision, deep learning, explainable AI, visual perception, CRAFT, MACO, Xplique">
    <meta name="author" content="Thomas Serre">
    
    <!-- Open Graph Meta Tags (for social media sharing) -->
    <meta property="og:title" content="Thomas Serre - Computational Neuroscience & AI">
    <meta property="og:description" content="Professor of Cognitive & Psychological Sciences and Computer Science at Brown University. Research at the intersection of neuroscience and AI.">
    <meta property="og:image" content="https://vivo.brown.edu/profile-images/a20/107/457/8fe/466/2b8/4d3/698/9fd/411/55/tserre_photo_.jpeg">
    <meta property="og:url" content="https://your-domain.com">
    
    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@tserre">
    <meta name="twitter:creator" content="@tserre">
    <meta name="twitter:title" content="Thomas Serre - Brown University">
    <meta name="twitter:description" content="Research in computational neuroscience and brain-inspired AI at Brown University">
    
    <!-- Structured Data (JSON-LD) for Google -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "Person",
        "name": "Thomas Serre",
        "jobTitle": "Thomas J. Watson, Sr. Professor of Science",
        "affiliation": [
            {
                "@type": "Organization",
                "name": "Brown University"
            },
            {
                "@type": "Organization", 
                "name": "Artificial and Natural Intelligence Toulouse Institute (ANITI)"
            }
        ],
        "url": "https://your-domain.com",
        "sameAs": [
            "https://scholar.google.com/citations?user=kZlPW4wAAAAJ",
            "https://github.com/serre-lab",
            "https://serre-lab.clps.brown.edu/",
            "https://x.com/tserre",
            "https://bsky.app/profile/thomasserre.bsky.social",
            "https://www.linkedin.com/in/thomasserre/"
        ],
        "alumniOf": {
            "@type": "Organization",
            "name": "MIT"
        }
    }
    </script>
</head>
<img src="https://vivo.brown.edu/profile-images/a20/107/457/8fe/466/2b8/4d3/698/9fd/411/55/tserre_photo_.jpeg" alt="Thomas Serre" style="float: right; margin: 0 0 20px 20px; max-width: 200px; border-radius: 8px;">

Thomas Serre is the Thomas J. Watson, Sr. Professor of Science and Professor of <a href="https://brown.edu/academics/cognitive-linguistic-psychological-sciences">Cognitive & Psychological Sciences</a> and <a href="https://cs.brown.edu/">Computer Science</a> at Brown University.<br>

He is the Faculty Director of the <a href="https://ccv.brown.edu/">Center for Computation and Visualization</a> and Associate Director of the <a href="https://ccbs.carney.brown.edu/">Center for Computational Brain Science</a>. He also holds an International Chair in AI within the <a href="https://aniti.univ-toulouse.fr/">Artificial and Natural Intelligence Toulouse Institute (ANITI)</a> (France).<br>
Dr. Serre received his Ph.D. in Neuroscience from MIT (2006) and MSc in EECS from Télécom Bretagne, France (2000).<br>

His research focuses on understanding neural computations supporting visual perception, with particular emphasis on the role of recurrent and feedback processes in visual reasoning. His work bridges neuroscience and artificial intelligence, developing brain-inspired computational models that have been featured in outlets including BBC, The Economist, New Scientist, and Scientific American.<br>

Dr. Serre serves as area chair for top-tier conferences including CVPR, ICML, ICLR, and NeurIPS, and as section editor for PLOS Computational Biology.<br>

He received an NSF Early Career Award and DARPA Young Faculty Award. His team's work on human action recognition earned the IEEE PAMI Helmholtz Prize (2021) and Mark Everingham Prize (2022). <br><br>

<h2>Research</h2>

My research investigates the computational principles of biological vision to understand how the brain works and to build more human-like AI systems. I work at the intersection of neuroscience, cognitive science, and artificial intelligence<br><br>

<h3>Current Research Directions</h3>

<b>Human-AI Alignment in Vision</b><br>
We're developing methods to quantify and improve the alignment between deep neural networks and human visual processing. Our <a href="https://arxiv.org/abs/2504.16940">recent work</a> shows that despite impressive performance, current vision models still process information fundamentally differently from humans. Understanding these gaps is crucial for building more robust and interpretable AI systems and to understand the brain mechanisms that support human vision. Our <a href="https://github.com/serre-lab/Harmonization">harmonization procedure</a> aligns DNN and human visual strategies while improving classification performance. <i>Funded by NSF</i><br><br>

<b>Explainable AI for Scientific Discovery</b><br>
In collaboration with the <a href="https://aniti.univ-toulouse.fr/">Artificial and Natural Intelligence Toulouse Institute (ANITI)</a>, we're creating tools to understand and interpret deep learning models. Our <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Fel_CRAFT_Concept_Recursive_Activation_FacTorization_for_Explainability_CVPR_2023_paper.pdf">CRAFT framework</a> (CVPR 2023) and <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/76d2f8e328e1081c22a77ca0fa330ca5-Abstract-Conference.html">MACO approach</a> (NeurIPS 2023) help researchers peek inside the "black box" of AI. These methods are implemented in our open-source toolboxes <a href="https://github.com/deel-ai/xplique">Xplique</a> and <a href="https://github.com/serre-lab/Horama">Horama</a>. See our tools in action: <a href="https://serre-lab.github.io/Lens/">LENS</a> and <a href="https://serre-lab.github.io/LeafLens/">LeafLens</a>. We're now extending this work to build <a href="https://www.arxiv.org/abs/2509.17280">foundation models for neuroscience and cognitive science</a>. <i>International Chair in AI, ANITI</i><br><br>
<b>Cortical Feedback and Visual Reasoning</b><br>
We're reverse-engineering how feedback connections in the brain enable complex visual reasoning and mental simulation. Our <a href="https://www.cell.com/current-biology/fulltext/S0960-9822(24)01380-0">recent work</a> reveals that both monkeys and recurrent neural networks use internal "mental simulations" to solve challenging visual tasks—suggesting deep computational principles shared between biological and artificial intelligence. <i>Funded by ONR</i><br><br>

<b>Cognitive Benchmarks for AI Visual Reasoning</b><br>
We develop rigorous cognitive-psychology-inspired tests to evaluate how AI systems compare to humans in fundamental visual reasoning tasks. Our <a href="https://openreview.net/forum?id=WP4WdXBWGn">3D-PC benchmark</a> (NeurIPS 2024) reveals that while humans effortlessly understand 3D scenes from different viewpoints, current AI struggles with visual perspective-taking. Our <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/448f4302dc3f72a8d0f6b65f464ceee4-Abstract-Conference.html">compositional visual reasoning benchmark</a> (NeurIPS 2022) tests whether models can flexibly combine visual concepts—a hallmark of human intelligence that remains challenging for AI. Even seemingly simple tasks like <a href="https://proceedings.neurips.cc/paper_files/paper/2018/hash/a860a7886d7c7e2a8d3eaac96f76dc0d-Abstract.html">same-different judgments</a> (NeurIPS 2018) expose fundamental limitations in how neural networks process visual relationships. These benchmarks don't just measure performance; they diagnose specific computational gaps between human and machine vision, guiding us toward more human-like AI architectures.<br><br>

<h2>Teaching</h2>

I teach computational courses at the interface between natural and artificial intelligence, bridging neuroscience, cognitive science, and AI.<br><br>

<b>CPSY 1291: Computational Methods for Mind, Brain & Behavior</b><br>
<i>Advanced Undergraduate/Graduate, Fall Semester</i><br>
A broad introduction to NeuroAI combining lectures with hands-on programming assignments. Students explore computational models of brain and cognition, classical machine learning algorithms, and modern deep learning architectures.<br><br>

<b>CPSY 1950: Deep Learning in Brains, Minds & Machines</b><br>
<i>Advanced Undergraduate/Graduate, Spring Semester</i><br>
A seminar-style exploration of cutting-edge research at the intersection of natural and artificial intelligence. Students engage with recent papers and develop critical perspectives on how biological and artificial systems process information.<br><br>

<h2>Selected Recent Publications</h2>

- T. Serre & E. Pavlick (2025). <a href="https://arxiv.org/abs/2509.17280">From Prediction to Understanding: Will AI Foundation Models Transform Brain Science?</a> <i>arXiv preprint</i>.<br>
- D. Linsley, P. Feng & T. Serre (2025). <a href="https://arxiv.org/abs/2504.16940">Better artificial intelligence does not mean better models of biology</a>. <i>arXiv preprint</i>.<br>
- A. Ahuja et al. (2024). <a href="https://www.cell.com/current-biology/fulltext/S0960-9822(24)01380-0">Monkeys engage in visual simulation to solve complex problems</a>. <i>Current Biology</i>.<br>
- T. Fel et al. (2023). <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/76d2f8e328e1081c22a77ca0fa330ca5-Abstract-Conference.html">MACO: Unlocking feature visualization for deeper networks</a>. <i>NeurIPS</i>.<br>
- T. Fel et al. (2023). <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Fel_CRAFT_Concept_Recursive_Activation_FacTorization_for_Explainability_CVPR_2023_paper.pdf">CRAFT: Concept Recursive Activation FacTorization for Explainability</a>. <i>CVPR</i>.<br><br>

<h2>Lab & Resources</h2>

For more information about our research, team, and open-source tools:<br>
- <a href="https://serre-lab.clps.brown.edu/">Serre Lab website</a><br>
- <a href="https://scholar.google.com/citations?user=kZlPW4wAAAAJ&hl=en&oi=ao">Google Scholar</a> <br>
- <a href="https://github.com/serre-lab">GitHub</a> - Code and tools<br>
- <a href="https://github.com/deel-ai/xplique">Xplique</a> - Explainable AI toolbox<br><br>

<p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
